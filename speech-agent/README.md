# English Accent Classification Agent

This repository provides a complete end-to-end solution for extracting audio from video URLs and classifying English accents. You can run the project step-by-step in Google Colab by executing each of the 10 cells in order, or launch the entire pipeline via the provided Python script.

---

## üìÅ Repository Structure

* `agent_speech_model` ‚Äî Standalone script that replicates the Colab notebook logic and launches the Gradio interface.
* `README.md` ‚Äî This documentation file.
* (Recommended) Colab notebook: `agent_speech_model.ipynb` with the same content as the script, autogenerated by Colab.

---

## ‚öôÔ∏è Prerequisites

* **Python**: 3.8 or above
* **Google Colab** (for notebook execution)
* **Local environment**:

  * `pip` for dependency installation and `!pip` for terminal commands in Google Colab.
  * System packages: `ffmpeg`, `sox`, `libsox-fmt-all` (installed automatically in Colab cells)

---

## üöÄ Executing in Google Colab (Cell by cell/One-shot Script)
‚Äî it can be created in Google Colab by running every cell one by one (the last one will open our agent and the interface) or directly through one script that will finally open our agent. 

- if not working with the script, copying the code cell by cell/one-shot with work
- the accuracy ratio needs to be further improved to ensure the accurate quality of the output but it works for this purpose

1. **Open the Colab notebook**

   * Navigate to the `.ipynb` file or open via the shared Colab link.
2. **Run cells 1‚Äë10 sequentially**

   1. **Cell 1**: Installs all Python and system dependencies (`speechbrain`, `torch`, `gradio`, `yt-dlp`, etc.).
   2. **Cell 2**: Imports libraries, configures device, model names, and temp directories.
   3. **Cells 3‚Äì5**: Defines functions for model loading, audio preprocessing (noise reduction, bandpass filtering), and robust audio extraction from various video sources.
   4. **Cell 6**: Implements accent classification logic with confidence scoring and warnings.
   5. **Cells 7‚Äì8**: Wraps processing steps in `process_video_url`, formats results, and provides cleanup utilities.
   6. **Cell 9**: Builds a Gradio interface with examples and usage tips.
   7. **Cell 10**: Preloads models, tests system components, cleans up, and launches Gradio (with an optional public share URL).
3. **Interact with the Interface**

   * Once the final cell finishes, click the displayed URL to open the web interface.
   * Paste a YouTube, Loom, Vimeo, or direct MP4/MOV/AVI URL and click **Analyze Accent**.

   - See Screenshots of how the interface should look via Google Colab and opened via direct link that will be prompted after the final run

> **Note**: Removed service-account mounting steps to simplify setup. Any required credentials for private videos should be configured separately.


## üîç Improvements & Future Work

1. **Confidence Threshold Tuning**

   * Adjust the softmax temperature or minimum confidence ratio to bias results toward higher certainty.

2. **Custom Model Training**

   * Train from scratch using the latest 2025 research in accent modeling for improved domain coverage.

3. **Feedback Loop**

   * Allow users to correct misclassifications and incorporate the labeled data into incremental training.

4. **Deployment & Scalability**

   * Containerize with Docker and orchestrate with Kubernetes or serverless for production-grade deployment.

5. **Interface Upgrades**

   * Real-time audio visualization, confidence heatmaps, and multi-language support.

---

*End of README.md*
